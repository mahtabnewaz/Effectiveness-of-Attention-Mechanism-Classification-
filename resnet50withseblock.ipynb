{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Data-Pre-Processing","metadata":{}},{"cell_type":"markdown","source":"## Library Import","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models\n\n# For handling Excel files\nimport openpyxl\n\n# For progress bars\nfrom tqdm.notebook import tqdm\n\n# Setting plot style\nsns.set(style=\"whitegrid\")\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:38.277791Z","iopub.execute_input":"2024-10-21T17:25:38.278494Z","iopub.status.idle":"2024-10-21T17:25:44.481724Z","shell.execute_reply.started":"2024-10-21T17:25:38.278450Z","shell.execute_reply":"2024-10-21T17:25:44.480930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Directory","metadata":{}},{"cell_type":"code","source":"import os\n\n# Define the base directory\nbase_dir = '/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset'\n\n# List all files and directories in the base directory\nprint(\"Contents of the base directory:\")\nprint(os.listdir(base_dir))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:44.483433Z","iopub.execute_input":"2024-10-21T17:25:44.484359Z","iopub.status.idle":"2024-10-21T17:25:44.498556Z","shell.execute_reply.started":"2024-10-21T17:25:44.484312Z","shell.execute_reply":"2024-10-21T17:25:44.497676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"import glob\n\n# Find all metadata files in the base directory\nmetadata_files = glob.glob(os.path.join(base_dir, '*.metadata.xlsx'))\n\nprint(\"\\nFound Metadata Files:\")\nfor file in metadata_files:\n    print(os.path.basename(file))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:44.499531Z","iopub.execute_input":"2024-10-21T17:25:44.499829Z","iopub.status.idle":"2024-10-21T17:25:44.506090Z","shell.execute_reply.started":"2024-10-21T17:25:44.499798Z","shell.execute_reply":"2024-10-21T17:25:44.505200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Four Class and total entries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\nroot_dir = '/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset'\n\nclasses = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n\n# Initialize a dictionary to hold metadata DataFrames\nmetadata = {}\n\nfor cls in classes:\n    # Special case for 'Viral Pneumonia'\n    if cls == 'Viral Pneumonia':\n        metadata_path = os.path.join(root_dir, 'Viral Pneumonia.metadata.xlsx')\n    else:\n        metadata_path = os.path.join(root_dir, f'{cls}.metadata.xlsx')\n        \n    if os.path.exists(metadata_path):\n        metadata_df = pd.read_excel(metadata_path)\n        metadata[cls] = metadata_df\n        print(f\"Loaded metadata for class: {cls} with {len(metadata_df)} entries.\")\n    else:\n        print(f\"Metadata file for class {cls} not found at {metadata_path}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:44.508706Z","iopub.execute_input":"2024-10-21T17:25:44.509051Z","iopub.status.idle":"2024-10-21T17:25:46.737553Z","shell.execute_reply.started":"2024-10-21T17:25:44.509011Z","shell.execute_reply":"2024-10-21T17:25:46.736585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect columns for each metadata DataFrame\nfor cls in classes:\n    if cls in metadata:\n        print(f\"\\nColumns in {cls} Metadata:\")\n        print(metadata[cls].columns)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:46.738669Z","iopub.execute_input":"2024-10-21T17:25:46.738989Z","iopub.status.idle":"2024-10-21T17:25:46.744907Z","shell.execute_reply.started":"2024-10-21T17:25:46.738955Z","shell.execute_reply":"2024-10-21T17:25:46.744029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class COVID19RadiographyDataset(Dataset):\n    def __init__(self, image_mask_pairs, transform=None, mask_transform=None):\n        \"\"\"\n        Args:\n            image_mask_pairs (list of tuples): List where each tuple contains (image_path, mask_path, label).\n            transform (callable, optional): Optional transform to be applied on an image.\n            mask_transform (callable, optional): Optional transform to be applied on a mask.\n        \"\"\"\n        self.image_mask_pairs = image_mask_pairs\n        self.transform = transform\n        self.mask_transform = mask_transform\n\n    def __len__(self):\n        return len(self.image_mask_pairs)\n\n    def __getitem__(self, idx):\n        image_path, mask_path, label = self.image_mask_pairs[idx]\n        \n        # Load image\n        image = Image.open(image_path).convert('RGB')  # Ensure 3 channels\n        \n        # Load mask\n        mask = Image.open(mask_path).convert('L')      # Grayscale for masks\n        \n        # Apply transforms\n        if self.transform:\n            image = self.transform(image)\n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n        \n        return image, mask, label\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:46.746178Z","iopub.execute_input":"2024-10-21T17:25:46.746573Z","iopub.status.idle":"2024-10-21T17:25:46.755331Z","shell.execute_reply.started":"2024-10-21T17:25:46.746528Z","shell.execute_reply":"2024-10-21T17:25:46.754518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define image transformations for training\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean\n                         std=[0.229, 0.224, 0.225])   # ImageNet std\n])\n\n# Define mask transformations (only resizing and tensor conversion)\nmask_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\n# Define image transformations for validation and testing\nval_test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:46.756381Z","iopub.execute_input":"2024-10-21T17:25:46.756658Z","iopub.status.idle":"2024-10-21T17:25:46.767555Z","shell.execute_reply.started":"2024-10-21T17:25:46.756628Z","shell.execute_reply":"2024-10-21T17:25:46.766812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the root directory of the dataset\nroot_dir = '/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset'\n\n# Define class names\nclasses = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n\n# Define label indices\nlabel_mapping = {cls: idx for idx, cls in enumerate(classes)}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:46.768460Z","iopub.execute_input":"2024-10-21T17:25:46.768781Z","iopub.status.idle":"2024-10-21T17:25:46.780303Z","shell.execute_reply.started":"2024-10-21T17:25:46.768749Z","shell.execute_reply":"2024-10-21T17:25:46.779450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize a list to hold all mapped data\nall_mapped_data = []\n\n# Iterate through each class and map images to masks\nfor cls in classes:\n    images_dir = os.path.join(root_dir, cls, 'images')\n    masks_dir = os.path.join(root_dir, cls, 'masks')\n    \n    # List all image filenames\n    image_filenames = os.listdir(images_dir)\n    \n    for img_filename in image_filenames:\n        img_path = os.path.join(images_dir, img_filename)\n        mask_path = os.path.join(masks_dir, img_filename)  # Assuming mask has same filename\n        \n        # Check if mask exists\n        if os.path.exists(mask_path):\n            all_mapped_data.append((img_path, mask_path, label_mapping[cls]))\n        else:\n            print(f\"Mask not found for image: {img_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:25:46.781366Z","iopub.execute_input":"2024-10-21T17:25:46.781660Z","iopub.status.idle":"2024-10-21T17:27:16.863660Z","shell.execute_reply.started":"2024-10-21T17:25:46.781622Z","shell.execute_reply":"2024-10-21T17:27:16.862887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to DataFrame for easier inspection\nmapped_df = pd.DataFrame(all_mapped_data, columns=['image_path', 'mask_path', 'label'])\n\n# Display the first few entries\nprint(\"Mapped DataFrame:\")\ndisplay(mapped_df.head())\n\n# Check total number of mapped samples\nprint(f\"Total images mapped: {len(mapped_df)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:16.868275Z","iopub.execute_input":"2024-10-21T17:27:16.868768Z","iopub.status.idle":"2024-10-21T17:27:16.903672Z","shell.execute_reply.started":"2024-10-21T17:27:16.868723Z","shell.execute_reply":"2024-10-21T17:27:16.902572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define split ratios\ntrain_ratio = 0.7\nval_ratio = 0.10\ntest_ratio = 0.20\n\n# Calculate split sizes\ntotal_size = len(mapped_df)\ntrain_size = int(train_ratio * total_size)\nval_size = int(val_ratio * total_size)\ntest_size = total_size - train_size - val_size\n\nprint(f\"Total samples: {total_size}\")\nprint(f\"Training samples: {train_size}\")\nprint(f\"Validation samples: {val_size}\")\nprint(f\"Testing samples: {test_size}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:16.905092Z","iopub.execute_input":"2024-10-21T17:27:16.905498Z","iopub.status.idle":"2024-10-21T17:27:16.911988Z","shell.execute_reply.started":"2024-10-21T17:27:16.905451Z","shell.execute_reply":"2024-10-21T17:27:16.911164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle the data\nfrom sklearn.model_selection import train_test_split\n\n# First split: Train and Temp (Val + Test)\ntrain_data, temp_data = train_test_split(\n    all_mapped_data,\n    test_size=(1 - train_ratio),\n    random_state=42,\n    stratify=[x[2] for x in all_mapped_data]  # Stratify based on labels\n)\n\n# Second split: Validation and Test\nval_size_adjusted = val_ratio / (val_ratio + test_ratio)  # Adjust validation size\nval_data, test_data = train_test_split(\n    temp_data,\n    test_size=(1 - val_size_adjusted),\n    random_state=42,\n    stratify=[x[2] for x in temp_data]\n)\n\nprint(f\"Training samples: {len(train_data)}\")\nprint(f\"Validation samples: {len(val_data)}\")\nprint(f\"Testing samples: {len(test_data)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:16.913079Z","iopub.execute_input":"2024-10-21T17:27:16.913371Z","iopub.status.idle":"2024-10-21T17:27:17.098785Z","shell.execute_reply.started":"2024-10-21T17:27:16.913340Z","shell.execute_reply":"2024-10-21T17:27:17.097885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n# Extract labels from training data\ntrain_labels = [sample[2] for sample in train_data]\n\n# Compute class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels),\n    y=train_labels\n)\n\nclass_weights = torch.tensor(class_weights, dtype=torch.float)\nprint(f\"Class Weights: {class_weights}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:17.100048Z","iopub.execute_input":"2024-10-21T17:27:17.100363Z","iopub.status.idle":"2024-10-21T17:27:17.198023Z","shell.execute_reply.started":"2024-10-21T17:27:17.100331Z","shell.execute_reply":"2024-10-21T17:27:17.197090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Dataset instances\ntrain_dataset = COVID19RadiographyDataset(train_data, transform=train_transform, mask_transform=mask_transform)\nval_dataset = COVID19RadiographyDataset(val_data, transform=val_test_transform, mask_transform=mask_transform)\ntest_dataset = COVID19RadiographyDataset(test_data, transform=val_test_transform, mask_transform=mask_transform)\n\n# Define batch size and number of workers\nbatch_size = 32\nnum_workers = 4  # Adjust based on your Kaggle kernel's CPU cores\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\nprint(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:17.199266Z","iopub.execute_input":"2024-10-21T17:27:17.199643Z","iopub.status.idle":"2024-10-21T17:27:17.208593Z","shell.execute_reply.started":"2024-10-21T17:27:17.199600Z","shell.execute_reply":"2024-10-21T17:27:17.207767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count class distribution in training set\ntrain_label_counts = pd.Series(train_labels).value_counts().sort_index()\n\n# Create a bar plot\nplt.figure(figsize=(8,6))\nsns.barplot(x=classes, y=train_label_counts.values, palette='viridis')\nplt.title('Training Set Class Distribution')\nplt.xlabel('Class')\nplt.ylabel('Number of Images')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:17.209907Z","iopub.execute_input":"2024-10-21T17:27:17.210736Z","iopub.status.idle":"2024-10-21T17:27:17.713564Z","shell.execute_reply.started":"2024-10-21T17:27:17.210664Z","shell.execute_reply":"2024-10-21T17:27:17.712721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img, title=None):\n    \"\"\"\n    Displays a tensor as an image.\n    \n    Args:\n        img (Tensor): Image tensor.\n        title (str, optional): Title for the image.\n    \"\"\"\n    img = img.numpy().transpose((1, 2, 0))\n    img = np.clip(img * np.array([0.229, 0.224, 0.225]) + \n                 np.array([0.485, 0.456, 0.406]), 0, 1)\n    plt.imshow(img)\n    if title:\n        plt.title(title)\n    plt.axis('off')\n\ndef show_batch(loader, classes, num_images=8):\n    \"\"\"\n    Displays a batch of images with their masks and labels.\n    \n    Args:\n        loader (DataLoader): DataLoader to fetch the batch.\n        classes (list): List of class names.\n        num_images (int): Number of images to display.\n    \"\"\"\n    images, masks, labels = next(iter(loader))\n    plt.figure(figsize=(20, 10))\n    for i in range(num_images):\n        plt.subplot(4, num_images//4, i+1)\n        imshow(images[i])\n        mask = masks[i].squeeze().numpy()\n        plt.imshow(mask, cmap='gray', alpha=0.3)\n        plt.title(classes[labels[i]])\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Show a batch from the training set\nshow_batch(train_loader, classes, num_images=8)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:17.714893Z","iopub.execute_input":"2024-10-21T17:27:17.715254Z","iopub.status.idle":"2024-10-21T17:27:21.134288Z","shell.execute_reply.started":"2024-10-21T17:27:17.715212Z","shell.execute_reply":"2024-10-21T17:27:21.133207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet50Baseline(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet50Baseline, self).__init__()\n        self.resnet = models.resnet50(pretrained=False)\n        num_ftrs = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n    \n    def forward(self, x):\n        x = self.resnet(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.136001Z","iopub.execute_input":"2024-10-21T17:27:21.136750Z","iopub.status.idle":"2024-10-21T17:27:21.143875Z","shell.execute_reply.started":"2024-10-21T17:27:21.136686Z","shell.execute_reply":"2024-10-21T17:27:21.142719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SEBlock(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SEBlock, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\nclass ResNet50WithSE(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet50WithSE, self).__init__()\n        self.resnet = models.resnet50(pretrained=False)\n        self.se = SEBlock(channel=2048, reduction=16)  # ResNet50's final conv layer has 2048 channels\n        num_ftrs = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n    \n    def forward(self, x):\n        x = self.resnet.conv1(x)\n        x = self.resnet.bn1(x)\n        x = self.resnet.relu(x)\n        x = self.resnet.maxpool(x)\n        \n        x = self.resnet.layer1(x)\n        x = self.resnet.layer2(x)\n        x = self.resnet.layer3(x)\n        x = self.resnet.layer4(x)\n        \n        x = self.se(x)  # Apply SE block\n        \n        x = self.resnet.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.resnet.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.145247Z","iopub.execute_input":"2024-10-21T17:27:21.146073Z","iopub.status.idle":"2024-10-21T17:27:21.157891Z","shell.execute_reply.started":"2024-10-21T17:27:21.146040Z","shell.execute_reply":"2024-10-21T17:27:21.156971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose model type\nmodel_type = 'se'  # Options: 'baseline', 'se'\n\nnum_classes = len(classes)\n\nif model_type == 'baseline':\n    model = ResNet50Baseline(num_classes=num_classes)\nelif model_type == 'se':\n    model = ResNet50WithSE(num_classes=num_classes)\nelse:\n    raise ValueError(\"Invalid model type selected.\")\n\n# Move the model to the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.159164Z","iopub.execute_input":"2024-10-21T17:27:21.159494Z","iopub.status.idle":"2024-10-21T17:27:21.863813Z","shell.execute_reply.started":"2024-10-21T17:27:21.159443Z","shell.execute_reply":"2024-10-21T17:27:21.862870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function with class weights\ncriterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n\n# Define optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Define learning rate scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.865061Z","iopub.execute_input":"2024-10-21T17:27:21.865362Z","iopub.status.idle":"2024-10-21T17:27:21.872555Z","shell.execute_reply.started":"2024-10-21T17:27:21.865330Z","shell.execute_reply":"2024-10-21T17:27:21.871709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25):\n    best_acc = 0.0\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n                dataloader = train_loader\n            else:\n                model.eval()   # Set model to evaluate mode\n                dataloader = val_loader\n            \n            running_loss = 0.0\n            running_corrects = 0\n            \n            # Iterate over data\n            for inputs, masks, labels in tqdm(dataloader, desc=phase.capitalize()):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # Zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # Forward\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    # Backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'train':\n                scheduler.step()\n            \n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n            \n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n            \n            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            \n            # Deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n        \n        print()\n    \n    print(f'Best Validation Acc: {best_acc:.4f}')\n    \n    # Load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, history\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.873781Z","iopub.execute_input":"2024-10-21T17:27:21.874081Z","iopub.status.idle":"2024-10-21T17:27:21.887195Z","shell.execute_reply.started":"2024-10-21T17:27:21.874050Z","shell.execute_reply":"2024-10-21T17:27:21.886392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define number of epochs\nnum_epochs = 25\n\n# Train the model\ntrained_model, history = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:27:21.888201Z","iopub.execute_input":"2024-10-21T17:27:21.888485Z","iopub.status.idle":"2024-10-21T18:31:14.276645Z","shell.execute_reply.started":"2024-10-21T17:27:21.888455Z","shell.execute_reply":"2024-10-21T18:31:14.275565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\ndef evaluate_model(model, dataloader, classes):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, masks, labels in tqdm(dataloader, desc='Testing'):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Classification Report\n    print(\"Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=classes))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10,8))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T18:31:14.278224Z","iopub.execute_input":"2024-10-21T18:31:14.278609Z","iopub.status.idle":"2024-10-21T18:31:14.288416Z","shell.execute_reply.started":"2024-10-21T18:31:14.278557Z","shell.execute_reply":"2024-10-21T18:31:14.287474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Evaluate the model on the test set\nevaluate_model(trained_model, test_loader, classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T18:31:14.289596Z","iopub.execute_input":"2024-10-21T18:31:14.290518Z","iopub.status.idle":"2024-10-21T18:31:37.852850Z","shell.execute_reply.started":"2024-10-21T18:31:14.290474Z","shell.execute_reply":"2024-10-21T18:31:37.851856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    # Plot Loss\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1)\n    plt.plot(epochs, history['train_loss'], 'bo-', label='Training Loss')\n    plt.plot(epochs, history['val_loss'], 'ro-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot Accuracy\n    plt.subplot(1,2,2)\n    plt.plot(epochs, history['train_acc'], 'bo-', label='Training Acc')\n    plt.plot(epochs, history['val_acc'], 'ro-', label='Validation Acc')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot training history\nplot_history(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T18:31:37.854302Z","iopub.execute_input":"2024-10-21T18:31:37.854622Z","iopub.status.idle":"2024-10-21T18:31:38.665836Z","shell.execute_reply.started":"2024-10-21T18:31:37.854585Z","shell.execute_reply":"2024-10-21T18:31:38.664661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_predictions(model, dataloader, classes, num_images=6):\n    model.eval()\n    images, masks, labels = next(iter(dataloader))\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    with torch.no_grad():\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n    \n    images = images.cpu().numpy()\n    masks = masks.cpu().numpy()\n    preds = preds.cpu().numpy()\n    labels = labels.cpu().numpy()\n    \n    plt.figure(figsize=(20, 10))\n    for i in range(num_images):\n        # Original Image\n        plt.subplot(num_images, 3, 3*i + 1)\n        img = images[i].transpose((1, 2, 0))\n        img = np.clip(img * np.array([0.229, 0.224, 0.225]) + \n                     np.array([0.485, 0.456, 0.406]), 0, 1)\n        plt.imshow(img)\n        plt.title(f\"True: {classes[labels[i]]}\")\n        plt.axis('off')\n        \n        # Mask\n        plt.subplot(num_images, 3, 3*i + 2)\n        plt.imshow(masks[i].squeeze(), cmap='gray')\n        plt.title(\"Mask\")\n        plt.axis('off')\n        \n        # Prediction\n        plt.subplot(num_images, 3, 3*i + 3)\n        plt.imshow(img)\n        plt.imshow(masks[i].squeeze(), cmap='gray', alpha=0.3)\n        plt.title(f\"Predicted: {classes[preds[i]]}\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Visualize sample predictions\nvisualize_predictions(trained_model, test_loader, classes, num_images=6)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T18:31:38.667270Z","iopub.execute_input":"2024-10-21T18:31:38.667628Z","iopub.status.idle":"2024-10-21T18:31:42.241719Z","shell.execute_reply.started":"2024-10-21T18:31:38.667593Z","shell.execute_reply":"2024-10-21T18:31:42.240711Z"},"trusted":true},"execution_count":null,"outputs":[]}]}